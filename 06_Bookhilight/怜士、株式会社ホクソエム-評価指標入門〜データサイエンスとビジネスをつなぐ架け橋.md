---
kindle-sync:
  bookId: '39908'
  title: 評価指標入門〜データサイエンスとビジネスをつなぐ架け橋
  author: 高柳 慎一、長田 怜士、株式会社ホクソエム
  asin: B0BT7GBF5L
  lastAnnotatedDate: '2025-06-02'
  bookImageUrl: 'https://m.media-amazon.com/images/I/71gaW0vJ+IL._SY160.jpg'
  highlightsCount: 46
---
# 評価指標入門〜データサイエンスとビジネスをつなぐ架け橋
## Metadata
* Author: [高柳 慎一、長田 怜士、株式会社ホクソエム](https://www.amazon.comundefined)
* ASIN: B0BT7GBF5L
* Reference: https://www.amazon.com/dp/B0BT7GBF5L
* [Kindle link](kindle://book?action=open&asin=B0BT7GBF5L)

## Highlights
学習にかかる実時間（学習するのに何分かかるのか？） ●最終的に出力される機械学習モデルのファイルサイズ（ストレージ上で何メガバイトを占めるのか？） ●特徴量を入力してから予測値を返すまでの時間（低レイテンシな予測が必要なときの評価指標となり得る）＊ — location: [123](kindle://book?action=open&asin=B0BT7GBF5L&location=123) ^ref-46554

---
4 — location: [127](kindle://book?action=open&asin=B0BT7GBF5L&location=127) ^ref-13364

---
推論フェーズにおける難しさは数理的な難しさというよりも、"リアルタイムに推論していくためにシステムとしてどう開発すべきなのか"や"推論結果や入力されてくる新たなデータの分布の監視はどうすべきか"などシステム開発としての側面が強く出てきます。 — location: [539](kindle://book?action=open&asin=B0BT7GBF5L&location=539) ^ref-26269

---
本書では、機械学習モデルの評価を 評価したい機械学習モデルを、評価指標というものさしで測り、ある基準となる値と"比較"し、その優劣を判断すること — location: [784](kindle://book?action=open&asin=B0BT7GBF5L&location=784) ^ref-45853

---
目的関数は、機械学習モデルのパラメータがその最大・最小化計算を通じて進むべき方向を示すもの（コラム「目的関数は機械学習モデルのダイナミクスを決めるもの」参照）です。一方、学習されたモデルの性能を人間が解釈可能な指標として自分たちが達成したい目標との近さを測るために評価指標が存在するのです。 — location: [855](kindle://book?action=open&asin=B0BT7GBF5L&location=855) ^ref-62863

---
ます。例えば二値分類問題のモデルをサポートベクターマシンというモデルで解くか、ロジスティック回帰というモデルで解くかによって、選択される目的関数は異なります。前者は通常、ソフトマージンを仮定すればヒンジ損失関数と正則化項を合わせたものが目的関数として使われ、後者はロジスティック損失が目的関数として使われます。この異なる目的関数の値自体を比較することは無意味であり、その値を見てモデルの優劣を判断することはできません。 — location: [865](kindle://book?action=open&asin=B0BT7GBF5L&location=865) ^ref-56953

---
パフォーマンスの飽和 セグメントの飽和 不気味の谷効果 代理目的変数の過剰最適化 — location: [999](kindle://book?action=open&asin=B0BT7GBF5L&location=999) ^ref-31527

---
（中略）より良いやり方がないため、A/Bテストをするタイミングやどのアルゴリズムをテストすべきかを決めるために大いにオフラインテストを活用しているが、オフラインテストがA/Bテストの結果を期待するほど高い精度で予測できている — location: [1071](kindle://book?action=open&asin=B0BT7GBF5L&location=1071) ^ref-59185

---
という事実を我々は見つけることができなかった。 — location: [1073](kindle://book?action=open&asin=B0BT7GBF5L&location=1073) ^ref-48185

---
二値分類問題を解き"再びECサイトを使うようになってくれるユーザ"として判定すべきか否かの 意思決定の分水嶺 となる閾値 の関数として利益を表現し、利益が最大になるようなを見つけるという戦略をとるのがよいでしょう。すなわち、 として利益（）をの関数とみなし、縦軸を利益、横軸を にとり、利益の 依存性を可視化してみるということです（図1.8）。 — location: [1149](kindle://book?action=open&asin=B0BT7GBF5L&location=1149) ^ref-29852

---
MAEを評価指標に選択してモデルを選ぶと、大きくはずした組合せを重視しないという意味でモデルの外れ値への当てはまりが悪くなるので、最大誤差が大きくなる傾向があります。 — location: [1859](kindle://book?action=open&asin=B0BT7GBF5L&location=1859) ^ref-24181

---
RMSLEの特徴としては、回帰モデルが実測値に比べて、より大きい値を予測することよりも、より小さい値を予測する場合に悪化するという点です。 — location: [1961](kindle://book?action=open&asin=B0BT7GBF5L&location=1961) ^ref-44492

---
これはビジネスへの応用としては、例えば販売数の予測モデルを作っているとして、在庫切れ（過小評価）よりも在庫過剰（過大評価）の方が現場として許容できる場合に相当します。 — location: [1966](kindle://book?action=open&asin=B0BT7GBF5L&location=1966) ^ref-58944

---
目的変数の値が丸められることで測定誤差のようなノイズを軽減させられる — location: [2239](kindle://book?action=open&asin=B0BT7GBF5L&location=2239) ^ref-64059

---
場合がある 回帰と比較して評価関数の設計が簡単になる 回帰では目的変数の値域を考慮して評価関数を決める必要がある（RMSEを評価指標に選択すると、値の大きな外れ値のデータの影響を受けやすく、MAPEを選択すると逆に値が小さいデータに影響を受けやすい） — location: [2240](kindle://book?action=open&asin=B0BT7GBF5L&location=2240) ^ref-58752

---
目的変数の値が持つ正負の情報量は、"目的変数の値がある閾値を超えるかどうかの情報量"と言い換えてもよいでしょう。 — location: [2285](kindle://book?action=open&asin=B0BT7GBF5L&location=2285) ^ref-59877

---
# labels=[1, 0]とすることでPositiveが左側の列に来るように調整 conf_matrix = confusion_matrix(y_val, y_val_hat, labels=[1, 0]) — location: [2403](kindle://book?action=open&asin=B0BT7GBF5L&location=2403) ^ref-27093

---
MCCの計算式は以下の式で表されます。 — location: [2457](kindle://book?action=open&asin=B0BT7GBF5L&location=2457) ^ref-10693

---
です。値域は－1～＋1をとり、予測結果と正解クラスがすべて一致すると＋1、予測結果と真のクラスがすべてが不一致だと－1、ランダムな予測をしていると0になります。 — location: [2463](kindle://book?action=open&asin=B0BT7GBF5L&location=2463) ^ref-32632

---
-scoreという評価指標を紹介します。 — location: [2540](kindle://book?action=open&asin=B0BT7GBF5L&location=2540) ^ref-44099

---
"モデルが攻撃的な投稿だと判定したときに間違っているケース（False Positive）"と"モデルが攻撃的な投稿でないと判定したが、実際は攻撃的な投稿だったケース（False Negative）"はどちらも同じくらいなくしたい "モデルが攻撃的な投稿ではないと判定して、実際に攻撃的な投稿ではないケース（True Negative）"は、どれだけ大量に分類されても人間が確認する必要がないものなので関心がない — location: [2558](kindle://book?action=open&asin=B0BT7GBF5L&location=2558) ^ref-6688

---
G-Mean（Geometric Mean） があります。G-MeanはTrue Positive Rate（Sensitivity；再現率）とTrue Negative Rate（Specificity；特異度）の両方のバランスをとるために幾何平均をとった指標 — location: [2573](kindle://book?action=open&asin=B0BT7GBF5L&location=2573) ^ref-59474

---
True Positive Rateは再現率と同じであり、Positiveの予測漏れがどの程度かを測る指標です。True Negative Rateという指標は、すべてのNegativeのデータを正しくNegativeと予測した割合を表しています。 — location: [2578](kindle://book?action=open&asin=B0BT7GBF5L&location=2578) ^ref-64596

---
このときx軸がFalse Positive Rate（FPR）、y軸がTrue Positive Rate（TPR）です。 — location: [2605](kindle://book?action=open&asin=B0BT7GBF5L&location=2605) ^ref-27014

---
この通り、True Positive RateおよびFalse Positive Rateの値は、PositiveとNegativeの分布の変化の影響を受けない評価指標を用いているため、ROC-AUCはクラスの分布には依存しない評価指標と言えます。 — location: [2687](kindle://book?action=open&asin=B0BT7GBF5L&location=2687) ^ref-42544

---
PR-AUCは、予測値を降順に並べたとき、上位の予測の正確さを重視するという特徴を持つ評価指標です。これにより、真のクラスにPositiveが少なくNegativeが多い不均衡データの場合に、ROC曲線よりもPR曲線を選ぶことがあります。 — location: [2702](kindle://book?action=open&asin=B0BT7GBF5L&location=2702) ^ref-29095

---
このとき、AUCは0.37でし — location: [2708](kindle://book?action=open&asin=B0BT7GBF5L&location=2708) ^ref-10262

---
PR曲線の良いところは、再現率をx軸に、適合率をy軸にとっているため、グラフを解釈しながら議論を進めやすい点にあります。 — location: [2724](kindle://book?action=open&asin=B0BT7GBF5L&location=2724) ^ref-29112

---
ビジネスサイドには作成したモデルのPR曲線を見せてどの閾値を使うのが良いかを相談する — location: [2728](kindle://book?action=open&asin=B0BT7GBF5L&location=2728) ^ref-11580

---
NegativeとPositiveをバランスよく評価したい場合にROC-AUCを使用し、Positiveが稀な不均衡データでPositiveが重要な場合にPR-AUCを使用します。 — location: [2730](kindle://book?action=open&asin=B0BT7GBF5L&location=2730) ^ref-11656

---
一方で、PR-AUCの値は評価用のデータのPositiveの数とデータの総数によって変わるため、常に0.08が最悪値であるとは限らない点に注意してください。 — location: [2763](kindle://book?action=open&asin=B0BT7GBF5L&location=2763) ^ref-53661

---
予測値が最低値のデータで真のクラスがPositiveをとるデータがあると評価値が大きく下がります。しかし、予測値が最大値のときに、真のクラスがNegativeをとるデータがあってもAUCに大きな影響はありません。 — location: [2856](kindle://book?action=open&asin=B0BT7GBF5L&location=2856) ^ref-23055

---
には"基本的な方針としては機械学習モデルの出力に応じて実行されるビジネス施策の結果から生じる売上とコストを考え、その双方を天秤にかけて考えること" — location: [2952](kindle://book?action=open&asin=B0BT7GBF5L&location=2952) ^ref-47848

---
9500, -500, 0, 0 — location: [3107](kindle://book?action=open&asin=B0BT7GBF5L&location=3107) ^ref-4054

テキスト通りなら9800, -200, 0, 0

---
# 予測したラベル y_val_hat = (y_val_hat_proba[:, 1] > proba).astype(int) — location: [3115](kindle://book?action=open&asin=B0BT7GBF5L&location=3115) ^ref-34082

予測値の確率を大きい順に並べて、それを閾値にした場合のConfusion Matrixを順次作成していく

---
ここではサンプリングを用いた Weighting という提案手法［Ting98］について紹介します。 — location: [3316](kindle://book?action=open&asin=B0BT7GBF5L&location=3316) ^ref-9312

---
Macro PrecisionはMicro Precisionと比較すると、各クラスのサンプル個数によらずクラスごとの評価を加味したいケースで適しています。一方で、Micro Precisionは、正解のクラスの個数に偏りがあり、サンプル個数が少ないクラスの重要度が低い場合に適しています。 — location: [3557](kindle://book?action=open&asin=B0BT7GBF5L&location=3557) ^ref-26390

---
Weighted Precisionはサンプル数が多いクラスのPrecisionほど重視する評価指標 — location: [3590](kindle://book?action=open&asin=B0BT7GBF5L&location=3590) ^ref-30931

---
実はRecallにおいてはWeighted RecallとMicro Recallは等価になります。 — location: [3675](kindle://book?action=open&asin=B0BT7GBF5L&location=3675) ^ref-57866

---
Macro F1-scoreは、クラスごとのF1-scoreを各クラスの検証用データのサンプル数にかかわらず同じ重みで平均しているため、全体で求める精度よりも各クラスのそれぞれの結果に影響します。 — location: [3722](kindle://book?action=open&asin=B0BT7GBF5L&location=3722) ^ref-65084

---
クラスに偏りのある不均衡データでは、Micro ROC-AUCは評価値が良くなる性質を持つ — location: [3851](kindle://book?action=open&asin=B0BT7GBF5L&location=3851) ^ref-12705

---
Macro ROC-AUCは少数派のクラスであっても、その分類結果の影響を受けやすいことがわかりました。 — location: [3916](kindle://book?action=open&asin=B0BT7GBF5L&location=3916) ^ref-33729

---
Micro ROC-AUCはどのクラスであるかは関心がなく、データ全体で正しい分類ができていてほしい場合に利用し、Macro ROC-AUCは各クラスを同等に重要であると考えたいときに利用します。 — location: [3942](kindle://book?action=open&asin=B0BT7GBF5L&location=3942) ^ref-13630

---
モデルであっても、極端な値をとるクラスがあればその影響を受けてしまうこともあります。 — location: [3970](kindle://book?action=open&asin=B0BT7GBF5L&location=3970) ^ref-52807

---
ですので、プロジェクトを進める際には、評価指標とは別に、"クラスごとに適合率、再現率、F1-scoreを算出する"、"混同行列を見る"といった、各クラスの分類性能を確認することも重要です。 — location: [3971](kindle://book?action=open&asin=B0BT7GBF5L&location=3971) ^ref-33934

---
満たす ここで、 偏った予測をするモデルが良い — location: [4013](kindle://book?action=open&asin=B0BT7GBF5L&location=4013) ^ref-14776

---

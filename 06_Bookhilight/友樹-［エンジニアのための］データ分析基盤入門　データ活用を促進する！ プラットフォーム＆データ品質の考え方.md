---
kindle-sync:
  bookId: '56316'
  title: ［エンジニアのための］データ分析基盤入門　データ活用を促進する！ プラットフォーム＆データ品質の考え方
  author: 斎藤 友樹
  asin: B09S5ZW33G
  lastAnnotatedDate: '2024-03-10'
  bookImageUrl: 'https://m.media-amazon.com/images/I/71IFGFDH+XL._SY160.jpg'
  highlightsCount: 133
---
# ［エンジニアのための］データ分析基盤入門　データ活用を促進する！ プラットフォーム＆データ品質の考え方
## Metadata
* Author: [斎藤 友樹](https://www.amazon.comundefined)
* ASIN: B09S5ZW33G
* Reference: https://www.amazon.com/dp/B09S5ZW33G
* [Kindle link](kindle://book?action=open&asin=B09S5ZW33G)

## Highlights
シングルノード（ single node） 時代 は、ExcelやRDBを使った単一PC上の分析が主でした。 — location: [976](kindle://book?action=open&asin=B09S5ZW33G&location=976) ^ref-51951

---
2010年代になると、データをできる限り集め、複数のシングルノードを束ねて一つのノードのように操作を行うマルチノードすなわちクラスター（ cluster）上でデータを操作する時代が始まります。 — location: [993](kindle://book?action=open&asin=B09S5ZW33G&location=993) ^ref-46910

---
・データを保存するサービス ・データを処理（計算能力を提供する）するサービス ・メタデータと連携するサービス ・SQLでデータを参照するサービス — location: [1029](kindle://book?action=open&asin=B09S5ZW33G&location=1029) ^ref-5490

---
シェアードオンリーデータにおいて、データはAmazon S3やGoogle Cloud Storageといったスケール可能なクラウドストレージに配置を行い、計算リソースはAmazon EMRやAmazon Redshift、Amazon Athena、Google DataprocやGoogle BigQueryといったプロダクトがデータを利用します。 — location: [1064](kindle://book?action=open&asin=B09S5ZW33G&location=1064) ^ref-33460

---
本書では、 データ分析基盤 といえば、データレイク、データウェアハウス、データマートの3つを合わせたものを指します — location: [1084](kindle://book?action=open&asin=B09S5ZW33G&location=1084) ^ref-20135

---
データレイクでは、SQLにてデータを分析するというよりPythonやApache Sparkといったプログラミング言語が活躍する領域です。 — location: [1096](kindle://book?action=open&asin=B09S5ZW33G&location=1096) ^ref-63092

---
データウェアハウスとデータマートの間にはグレーな境界線があるだけで、両者の間に明確な線引きはありません。しかし、データマートのほうがよりユーザーフェイシング（ user facing、ユーザーに近い）という特徴がデータウェアハウスと異なるところではないでしょうか。 — location: [1115](kindle://book?action=open&asin=B09S5ZW33G&location=1115) ^ref-33284

---
しかし、Apache Zookeeperというノード間のやり取りを取り持つ技術が進展してから、急激に分散処理がコモディティ化（ commoditization）します。そこで認知され始めたのが「Hadoop」です。 — location: [1182](kindle://book?action=open&asin=B09S5ZW33G&location=1182) ^ref-15939

---
シングルノードで行われるスレッド処理を行う場合は、この文字をカウントする処理を、スレッドと呼ばれる別プロセスを立ち上げ別々のスレッド（たとえばAスレッドはI am fine担当、BスレッドはI am good担当）でamの数をカウントし、答えを出すということをしていました。 しかし、分散処理においては、スレッドの代わりに別々のノード（たとえばAノードはI am fine、BノードはI am good担当）でamの数をカウントし、答えを出すというしくみです。 スレッド処理と分散処理の違いは、処理性能を無限にスケールできるか否かという点にあります。 — location: [1190](kindle://book?action=open&asin=B09S5ZW33G&location=1190) ^ref-25702

---
・分散システムの構築管理 ・データの取り込みやETLを通したデータパイプラインの最適化 ・データが格納されているストレージの管理 ・ユーザーへのアクセス環境提供 — location: [1415](kindle://book?action=open&asin=B09S5ZW33G&location=1415) ^ref-4114

---
データエンジニアのボトルネックもあり、時代の流れのなかで DataOps（ Data operations）という考えが生まれました — location: [1522](kindle://book?action=open&asin=B09S5ZW33G&location=1522) ^ref-39022

---
従来のモデルではデータエンジニアが調整から開発まですべてを行い、本来価値を見いだすべきところへの集中ができない実情がありました。そこで、本来のエンジニア業務へ集中させることはできないかということから始まった考え方がセルフサービスです。 — location: [1560](kindle://book?action=open&asin=B09S5ZW33G&location=1560) ^ref-37400

---
バッチ処理もストリーミング処理も、適切な パーティション や ファイルフォーマット、 圧縮、 処理エンジン を利用して データパイプラインの処理速度 を少しでも上げましょう。 — location: [1646](kindle://book?action=open&asin=B09S5ZW33G&location=1646) ^ref-44480

---
・より少ないプロダクトで ・より障害が発生しにくく ・すぐに復旧ができる — location: [1672](kindle://book?action=open&asin=B09S5ZW33G&location=1672) ^ref-44964

---
❶ コレクティングレイヤー ➡ データを集める ❷ プロセシングレイヤー ➡ データを処理する ❸ ストレージレイヤー ➡ データを保持する ❹ アクセスレイヤー ➡ データを利用する — location: [1694](kindle://book?action=open&asin=B09S5ZW33G&location=1694) ^ref-63573

---
・ストリーミング（ streaming） ➡ 絶え間なくデータを収集する ・バッチ（ batch） ➡ 一定以上の塊のデータを収集する ・プロビジョニング（ provisioning） ➡ ひとまず仮にデータを配置する — location: [1711](kindle://book?action=open&asin=B09S5ZW33G&location=1711) ^ref-19704

---
・ETL（ Extract transform load） ・データラングリング（ data wrangling） ・暗号化（ encryption） — location: [1718](kindle://book?action=open&asin=B09S5ZW33G&location=1718) ^ref-42042

---
・データ品質 — location: [1720](kindle://book?action=open&asin=B09S5ZW33G&location=1720) ^ref-3486

---
計算/メタデータ計算 — location: [1720](kindle://book?action=open&asin=B09S5ZW33G&location=1720) ^ref-32296

---
すべてこのストレージレイヤーに対して行われるためより故障耐性が高く高速な処理を行えるディスクが求められます。 — location: [1729](kindle://book?action=open&asin=B09S5ZW33G&location=1729) ^ref-19640

---
車に付けられたセンサーデータや、家電に付けられた温度センサーなどのIoTデバイスからのデータであったり、Webサイト上のユーザーの回遊ログなどはストリーミングデータにあたります。 — location: [1773](kindle://book?action=open&asin=B09S5ZW33G&location=1773) ^ref-20096

---
リアルタイムのような速度は求められませんが、ジョブの数が多くなりがちなのでジョブのスループット（ throughput）などを上げる工夫が求められます。 — location: [1783](kindle://book?action=open&asin=B09S5ZW33G&location=1783) ^ref-63279

---
技術的な面よりもライフサイクルなど運用面を事前に検討する必要があります。 — location: [1797](kindle://book?action=open&asin=B09S5ZW33G&location=1797) ^ref-21349

---
バッチ処理においてはApache HiveやApache Sparkなどが使われます（ — location: [1814](kindle://book?action=open&asin=B09S5ZW33G&location=1814) ^ref-23652

---
現在ではETLというより「ELT」が — location: [1820](kindle://book?action=open&asin=B09S5ZW33G&location=1820) ^ref-65448

---
主流になっている節があります。 — location: [1821](kindle://book?action=open&asin=B09S5ZW33G&location=1821) ^ref-19318

---
RedshiftやBigQueryが持つ潤沢なリソースを使って、一気に変換まで実行するほうが効率が良いためです。 — location: [1823](kindle://book?action=open&asin=B09S5ZW33G&location=1823) ^ref-52737

---
データラングリング（ data wrangling）とは、非構造データを構造データにしたり、付加価値を付ける作業を指します — location: [1827](kindle://book?action=open&asin=B09S5ZW33G&location=1827) ^ref-58854

---
・データストラクチャリング（ data structuring） ・データクレンジング（ data cleansing） ・データエンリッチング（ data enriching） — location: [1841](kindle://book?action=open&asin=B09S5ZW33G&location=1841) ^ref-41652

---
ETLはより速度や保守性などを考慮してフォーマルに行われるという面がとくに違います。 — location: [1893](kindle://book?action=open&asin=B09S5ZW33G&location=1893) ^ref-44389

---
データ活用型のマスターデータ管理は、データ分析基盤以外のシステムでマスターデータを生成し、それらのマスターデータを集約し統合することでデータ分析基盤としてのマスターを作成する方法です。 — location: [2014](kindle://book?action=open&asin=B09S5ZW33G&location=2014) ^ref-35750

---
・ビジネスメタデータ（ 例 テーブル定義やドメイン知識） — location: [2037](kindle://book?action=open&asin=B09S5ZW33G&location=2037) ^ref-28831

---
・テクニカルメタデータ（ 例 ログデータや技術詳細、データ品質、データプロファイリング情報） ・オペレーショナルメタデータ（ 例 操作履歴など） — location: [2038](kindle://book?action=open&asin=B09S5ZW33G&location=2038) ^ref-60536

---
・Google DataCatalog — location: [2057](kindle://book?action=open&asin=B09S5ZW33G&location=2057) ^ref-50748

---
データウェアハウスとデータレイクの半々くらいのイメージを持つと良いだろう。 — location: [2085](kindle://book?action=open&asin=B09S5ZW33G&location=2085) ^ref-13843

---
❶ ストレージレイヤーのファイルをコピーや編集して渡す — location: [2186](kindle://book?action=open&asin=B09S5ZW33G&location=2186) ^ref-12289

---
❷ ストレージレイヤーのファイルを直接参照させる — location: [2192](kindle://book?action=open&asin=B09S5ZW33G&location=2192) ^ref-54157

---
アカウントごとに役割を分業し、担当することでアサインはアカウント単位となり必要とするスキルセットは少なくて済みます。 — location: [2226](kindle://book?action=open&asin=B09S5ZW33G&location=2226) ^ref-5391

---
・データ分析基盤へのオペレーションを提供 ・メタデータの取得/更新 ・NoSQLに格納された、レコメンド結果や機械学習データなどスモールデータシステム向けのデータ提供 — location: [2233](kindle://book?action=open&asin=B09S5ZW33G&location=2233) ^ref-2387

---
❶ ローゾーン ❷ ゴールドゾーン ❸ ステージングゾーン ❹ クォレンティーンゾーン ❺ テンポラリーゾーン — location: [2465](kindle://book?action=open&asin=B09S5ZW33G&location=2465) ^ref-37399

---
データの削除であれば、事前にIAMに対して 削除 タグが付いたものを参照不可に設定しておき、削除が必要になった時にデータに対して 削除 のタグを付けることで一斉に参照不可になります（あとは、タイミングを見てデータを削除する）。 — location: [2516](kindle://book?action=open&asin=B09S5ZW33G&location=2516) ^ref-64395

---
GAパターンの場合は、チェックをする人がボトルネックもしくはSPOF（ Single point of failre）になってしまう — location: [2553](kindle://book?action=open&asin=B09S5ZW33G&location=2553) ^ref-63856

---
また、プロビジョニングパターンにも同様の問題があるといえます。 — location: [2558](kindle://book?action=open&asin=B09S5ZW33G&location=2558) ^ref-29926

---
ビッグデータの世界では、テーブルの定義と実データが明確に分離されています。 — location: [2607](kindle://book?action=open&asin=B09S5ZW33G&location=2607) ^ref-23332

---
データとテーブル定義が分離されているため、テーブルの定義を作成する際には実際のデータがどこに存在するのかを指し示す必要があります。その指定を ロケーション（ location）と呼びます。 — location: [2610](kindle://book?action=open&asin=B09S5ZW33G&location=2610) ^ref-55627

---
データ分析基盤では、テーブルに配置されたデータを パーティション（ partition）と呼ばれる区切りに分けて保存していきます。 — location: [2623](kindle://book?action=open&asin=B09S5ZW33G&location=2623) ^ref-28926

---
パーティションを分けない場合は、以下のようにデータを日々貯めることができません。 — location: [2636](kindle://book?action=open&asin=B09S5ZW33G&location=2636) ^ref-56645

---
パーティションを設定するメリットは、その時点でのスナップショットデータを残すことが可能であるという点です。 — location: [2645](kindle://book?action=open&asin=B09S5ZW33G&location=2645) ^ref-49798

---
復旧が手順が膨大になり大変な場合は、 バージョニング（ versioning） 注7 を検討してみても良いかもしれません。 — location: [2687](kindle://book?action=open&asin=B09S5ZW33G&location=2687) ^ref-29611

---
パーティションの粒度は細か過ぎても問題になります。 — location: [2692](kindle://book?action=open&asin=B09S5ZW33G&location=2692) ^ref-63579

---
原則データはオープンであるべきで、A部署の売り上げをB部署が閲覧できないというような状況は作らないことがよりデータの文化を醸成する上では重要なポイントです。 — location: [2718](kindle://book?action=open&asin=B09S5ZW33G&location=2718) ^ref-61687

---
です。そこで影響を最小限にするために デカップリング（ decupling） 図3.10 ❷ という考えがデータ分析基盤にも出てきます。 — location: [2761](kindle://book?action=open&asin=B09S5ZW33G&location=2761) ^ref-60548

---
ストレージレイヤーとプロセシングレイヤーの分離は基本的な戦略で、システムをアーキテクトする際にまず考慮したいポイントになります。 — location: [2814](kindle://book?action=open&asin=B09S5ZW33G&location=2814) ^ref-20072

---
データを貯めているS3やGCSには「データへのアクセスした人と場所」のログを記録する機能（ logging、ロギング）が備わっています。 — location: [2900](kindle://book?action=open&asin=B09S5ZW33G&location=2900) ^ref-9228

---
データバーチャライゼーション（ data virtualization）では、データを取り込まずともロケーションとして外部のデータソース（たとえばExcelなど）を指定しテーブルを作成します。作成したテーブルに対してSQLを通して分析が可能です 図3.14 注18。 — location: [3000](kindle://book?action=open&asin=B09S5ZW33G&location=3000) ^ref-13094

---
・BigQuery Omni — location: [3018](kindle://book?action=open&asin=B09S5ZW33G&location=3018) ^ref-14947

---
データ分析基盤で重要な技術選択のうちの一つが クラスター です。クラスターは一つの目的のために処理を行う複数ノードの集合体です。 — location: [3140](kindle://book?action=open&asin=B09S5ZW33G&location=3140) ^ref-36074

---
これらの処理はApache Sparkを使って実現できます。 — location: [3177](kindle://book?action=open&asin=B09S5ZW33G&location=3177) ^ref-63652

---
・Google Dataproc — location: [3240](kindle://book?action=open&asin=B09S5ZW33G&location=3240) ^ref-44820

---
そのため、分析のための環境をシンプルにするためにもMPPDBにすべてのデータを集め（SSoT）、MPPDB環境下で分析環境のほとんどの処理を行ってしまうことも選択肢の一つです 注6。 — location: [3280](kindle://book?action=open&asin=B09S5ZW33G&location=3280) ^ref-38010

---
MySQLやPostgreSQL、クラウドストレージからの取り込みで活躍するツールがダンプ（ dump）ツールです。 — location: [3345](kindle://book?action=open&asin=B09S5ZW33G&location=3345) ^ref-37728

---
プロデューサーがデータを配置するメッセージキュー内の場所を「トピック」といいます。 — location: [3384](kindle://book?action=open&asin=B09S5ZW33G&location=3384) ^ref-55904

---
Sparkはバッチ処理からストリーミング処理まで1つで完結することができる単一コンピューティングエンジンです。 — location: [3449](kindle://book?action=open&asin=B09S5ZW33G&location=3449) ^ref-34109

---
Apache Hive 注18 はFacebookによって開発された、SQLライクな分析体験を提供するプロダクトです。 — location: [3469](kindle://book?action=open&asin=B09S5ZW33G&location=3469) ^ref-33479

---
・Google DataFlow — location: [3490](kindle://book?action=open&asin=B09S5ZW33G&location=3490) ^ref-35096

---
Sparkがあればバッチ処理からストリーミング処理まで完結します。 — location: [3515](kindle://book?action=open&asin=B09S5ZW33G&location=3515) ^ref-35039

---
・AWS CLIやGoogle CLI（gcloud）などのコマンドラインやSDKを利用する — location: [3554](kindle://book?action=open&asin=B09S5ZW33G&location=3554) ^ref-1124

---
自分自身でファイルが同一か否かを表す値を計算することが必要になりますが、Linuxサーバーがあれば以下の — location: [3592](kindle://book?action=open&asin=B09S5ZW33G&location=3592) ^ref-62300

---
ように簡単に確認できます。 — location: [3593](kindle://book?action=open&asin=B09S5ZW33G&location=3593) ^ref-35763

---
syncコマンドの例は基本cpコマンドと実行結果は同じですが、冪等性を確保できる点がcpコマンドと異なる点 — location: [3617](kindle://book?action=open&asin=B09S5ZW33G&location=3617) ^ref-60807

---
ストリーミングデータの送受信でとくに気をつけるべき点は、データの送信遅延と — location: [3648](kindle://book?action=open&asin=B09S5ZW33G&location=3648) ^ref-13136

---
データ重複です。 — location: [3649](kindle://book?action=open&asin=B09S5ZW33G&location=3649) ^ref-11072

---
❶ 同じデータが2回送信される場合 ❷ 同じデータを2回メッセージキューから読み取ってしまう場合 ❸ クラスター内のノードが同時に同じデータをメッセージキューから読み取りに行く場合 — location: [3658](kindle://book?action=open&asin=B09S5ZW33G&location=3658) ^ref-59137

---
しかし、ストリーミングの場合はウィンドウ（一定の間隔で時間を区切り処理を行うこと）内での重複削除のみ有効で、ウィンドウ間での重複削除には対応していません。 — location: [3686](kindle://book?action=open&asin=B09S5ZW33G&location=3686) ^ref-62243

---
❶ ETL処理を定義ファイルベースで記載することができること（CI/CD 注33 が行いやすくなる） ❷ 再実行時に、同じ結果が保証される冪等性があること ❸ 途中からやり直し（リトライ）ができる機能を有していること — location: [3774](kindle://book?action=open&asin=B09S5ZW33G&location=3774) ^ref-7354

---
したがって、とあるものに特化したワークフロー（たとえばArgoなど）よりは汎用的にいろいろな場所で活躍できるワークフローエンジンがデータ分析基盤では好まれる傾向になります。 — location: [3793](kindle://book?action=open&asin=B09S5ZW33G&location=3793) ^ref-60178

---
4.3節（コレクティングレイヤー — location: [3804](kindle://book?action=open&asin=B09S5ZW33G&location=3804) ^ref-53920

---
の技術スタック）で紹介したEmbulkと親和性が良く、データエンジニアリングの世界では多く使われます。 — location: [3805](kindle://book?action=open&asin=B09S5ZW33G&location=3805) ^ref-32679

---
Apache Airflow 画面4.5 注38 はPythonで定義可能なワークフローエンジンで、Digdagに比べると自由度が出る反面、よりエンジニア向けの製品に分類されます。 — location: [3827](kindle://book?action=open&asin=B09S5ZW33G&location=3827) ^ref-9756

---
ymlは構造化されたデータを表現するためのフォーマットで、設定ファイルの記述によく使われています。 — location: [3870](kindle://book?action=open&asin=B09S5ZW33G&location=3870) ^ref-52357

---
しかし、JSONやCSVはデータレイクでは利用できますが、それ以外では利用を避けた方が良く、その点についてまずは確認しておきましょう。 — location: [3890](kindle://book?action=open&asin=B09S5ZW33G&location=3890) ^ref-51551

---
何億のレコードを同時に処理を行うデータ分析基盤において、CSVやJSONは処理が分散されず 注41、分散されない 注42 場合、1つのノードで処理を行うことになってしまうため非効率になります。 — location: [3894](kindle://book?action=open&asin=B09S5ZW33G&location=3894) ^ref-7942

---
列指向フォーマットはデータ分析利用に特化しており、行指向フォーマットはIoTやWebの回遊ログなどの収集時に発生する高速なレコード処理（ただし、ビッグデータシステムの場合はレコードの追加がメイン）に適しています。 — location: [3909](kindle://book?action=open&asin=B09S5ZW33G&location=3909) ^ref-10831

---
注目されているAvroの特徴は開発スピードの違いを吸収することができるということです。 — location: [3940](kindle://book?action=open&asin=B09S5ZW33G&location=3940) ^ref-18449

---
後方互換性とは、新しい製品が、古い製品を扱えることを指します。前方互換性とは、古い製品が新しい — location: [3944](kindle://book?action=open&asin=B09S5ZW33G&location=3944) ^ref-24862

---
製品を扱えることを指します。 — location: [3945](kindle://book?action=open&asin=B09S5ZW33G&location=3945) ^ref-41282

---
フォーマットと圧縮形式の組み合わせによってファイルがスプリッタブル（分割可能）か、そうでないかというデータ分析基盤の成立/不成立を決定する技術要素が出てきます。 — location: [4011](kindle://book?action=open&asin=B09S5ZW33G&location=4011) ^ref-54171

---
CSVやJSONを利用するときには「bz2」を使うことです。bz2以外のフォーマットで圧縮してしまうとファイルがスプリッタブルではなくなってしまうため、後続のプロセシングレイヤーでの処理に時間がかかってしまいます。 — location: [4026](kindle://book?action=open&asin=B09S5ZW33G&location=4026) ^ref-13823

---
・クラウドストレージ ➡ S3やGCSなど ・プロダクトストレージ ➡ Amazon RedshiftやGoogle BigQueryなどの — location: [4036](kindle://book?action=open&asin=B09S5ZW33G&location=4036) ^ref-7744

---
MPPDBの内部にデータを保持する ・オンプレミスにおけるストレージ ➡ オンプレミスで利用されるSSD（ Solid-state drive）などを搭載したストレージ — location: [4039](kindle://book?action=open&asin=B09S5ZW33G&location=4039) ^ref-47073

---
プロダクトストレージ（ product storage）は特定のプロダクトの内部にデータを保存する方法です。たとえば、Amazon RedshiftやGoogle BigQueryそしてSnowflakeといったベンダーに依存していないプラットフォームも存在します。 — location: [4056](kindle://book?action=open&asin=B09S5ZW33G&location=4056) ^ref-23174

---
データストレージにデータを配置する際の注意点として、「スモールファイル」「データスキューネス」について見ておきましょう。 — location: [4097](kindle://book?action=open&asin=B09S5ZW33G&location=4097) ^ref-59828

---
ビッグデータを扱うプロダクトは1KB（ Kilobyte）が1億個存在するより、100MBが100個の方が処理が得意です — location: [4101](kindle://book?action=open&asin=B09S5ZW33G&location=4101) ^ref-1459

---
ビッグデータを扱うプロダクトではファイルが2つ以上存在していた場合、1KBと1GBのデータを処理するよりも500.1MBと500MBのファイル2つを処理する方が得意です — location: [4121](kindle://book?action=open&asin=B09S5ZW33G&location=4121) ^ref-47808

---
Presto 注65 はJavaで書かれたインメモリー型のクエリーエンジンです。Prestoのクエリーエンジンで実行されるSQLのことを「PrestoSQL」と呼びます — location: [4267](kindle://book?action=open&asin=B09S5ZW33G&location=4267) ^ref-14370

---
Hiveは途中の計算結果をディスクに吐き出しながら 注67 処理を進めるのに対し、Prestoはメモリー内（ in-memory）のみで処理を完結させます（ディスクにスピルする設定もある）。 — location: [4270](kindle://book?action=open&asin=B09S5ZW33G&location=4270) ^ref-35093

---
PrestoはHiveに比べ高速に動作します。 — location: [4274](kindle://book?action=open&asin=B09S5ZW33G&location=4274) ^ref-24404

---
自前で構築する以外にも、Prestoベースのサービスとして「Amazon Athena」 注68 が利用できます。 — location: [4277](kindle://book?action=open&asin=B09S5ZW33G&location=4277) ^ref-14638

---
Amazon RedshiftはPostgreSQLベースのSQLで構成されています。 — location: [4284](kindle://book?action=open&asin=B09S5ZW33G&location=4284) ^ref-15666

---
機能が制限されていたり、大人数で使うと処理が詰まってしまったりすることがあります。 — location: [4286](kindle://book?action=open&asin=B09S5ZW33G&location=4286) ^ref-53718

---
HiveSQL」と「SparkSQL」のみ互換性があります。 — location: [4321](kindle://book?action=open&asin=B09S5ZW33G&location=4321) ^ref-51127

---
❶ ETL処理やその他データ分析基盤に対する処理をラップ（ wrap）する ❷ メタデータ（第5章で後述）の提供 — location: [4329](kindle://book?action=open&asin=B09S5ZW33G&location=4329) ^ref-53013

---
ビッグデータシステムでは、 データとメタデータが明確に分かれている ため、このような制御を個別で行うことが可能になっているという点は押さえておきたいポイントです。 — location: [4511](kindle://book?action=open&asin=B09S5ZW33G&location=4511) ^ref-42297

---
メタデータは3種類に分けられます。テーブルやデータベースの特性を表す「ビジネスメタデータ」、技術的な内容を表す「テクニカルメタデータ」、システムの運用やデータの移動過程などで生成される「オペレーショナルメタデータ」です。 — location: [4554](kindle://book?action=open&asin=B09S5ZW33G&location=4554) ^ref-51763

---
リネージュ（データの紐付き）とプロバナンス（データの生まれや起源） — location: [4744](kindle://book?action=open&asin=B09S5ZW33G&location=4744) ^ref-21520

---
ルールの作成時に気をつけるポイントとしては、あまりスモールデータシステムや対向のシステムの都合に合わせ過ぎないことです。 — location: [4885](kindle://book?action=open&asin=B09S5ZW33G&location=4885) ^ref-41340

---
カーディナリティ（ cardinality）は、データがどれくらいバラけているのかを示す指標になります。 — location: [4917](kindle://book?action=open&asin=B09S5ZW33G&location=4917) ^ref-35762

---
デンシティNullはカラムレベルでの適用に対し、コンプリートネスはレコードレベルでの適用になります。 — location: [4985](kindle://book?action=open&asin=B09S5ZW33G&location=4985) ^ref-50256

---
そのことから、データカタログとはまだ「手元にない」データを登録し取り寄せるための、データのためのカタログになります。 — location: [5069](kindle://book?action=open&asin=B09S5ZW33G&location=5069) ^ref-14077

---
DIKWモデル（前出の 図6.A）では、データのステージを「Data」「Information」「Knowledge」「Wisdom」として定義しています。 — location: [5279](kindle://book?action=open&asin=B09S5ZW33G&location=5279) ^ref-39898

---
ユーザーがどうぞ自由に作って広めてください」というセルフサービスモデルに沿った形をとったほうが効率が良いのです。 — location: [5396](kindle://book?action=open&asin=B09S5ZW33G&location=5396) ^ref-44410

---
データ分析基盤においては、スキーマ設計において非正規化が推奨されているなど、RDBと設計思想が異なる部分があることも特徴です。 — location: [5432](kindle://book?action=open&asin=B09S5ZW33G&location=5432) ^ref-60695

---
❶ 防ぐ/予防（プリベンション/ prevension） ❷ 見つける/検知（ディテクション/ detection） ❸ 修正する/修理（リペア/ repair） — location: [5823](kindle://book?action=open&asin=B09S5ZW33G&location=5823) ^ref-36911

---
まずはデータ（およびデータ品質）は完璧ではないということを認識することが、データ品質を理解するための一歩になります。 — location: [5865](kindle://book?action=open&asin=B09S5ZW33G&location=5865) ^ref-17883

---
データ分析基盤とスモールデータシステムの決定的な違いは、アプリケーションを作成した人がそこに存在しないことにあります。 — location: [5870](kindle://book?action=open&asin=B09S5ZW33G&location=5870) ^ref-12184

---
❶ 正確性（ accuracy） ❷ 完全性（ completeness） ❸ 一貫性（ consistency） ❹ 有効性（ validity） ❺ 適時性（ timeliness） ❻ ユニーク性（ uniquness） — location: [5894](kindle://book?action=open&asin=B09S5ZW33G&location=5894) ^ref-57267

---
データ品質におけるレベルとは、データ品質の — location: [6082](kindle://book?action=open&asin=B09S5ZW33G&location=6082) ^ref-1318

---
チェックをテーブル単位で行うのか、カラム単位で行うのかといった、データ品質を行う粒度の基準になります。 — location: [6083](kindle://book?action=open&asin=B09S5ZW33G&location=6083) ^ref-29256

---
データの劣化によってたとえば、マスターデータの特定IDが削除されたがトランザクション系のデータは修正されていない場合データの紐付きを表現することができず、Nullが増加するということも考えられる。 — location: [6177](kindle://book?action=open&asin=B09S5ZW33G&location=6177) ^ref-58980

---
一般に精度が100％でないと困るということはなく1～5％の範囲でデータの不備は許容されることが一般的です。 — location: [6343](kindle://book?action=open&asin=B09S5ZW33G&location=6343) ^ref-62056

---
・タグクォリティ（ tag quality） — location: [6377](kindle://book?action=open&asin=B09S5ZW33G&location=6377) ^ref-12421

---
カラムやテーブルに対してどれだけテストが行われているかを示す指標。 — location: [6377](kindle://book?action=open&asin=B09S5ZW33G&location=6377) ^ref-7865

---
・キュレーションクォリティ（ curation quality） 人のメタデータへの介入がどれくらい存在するかを示す指標。 — location: [6383](kindle://book?action=open&asin=B09S5ZW33G&location=6383) ^ref-39617

---
SLO（ Service level objective）は、サーバーやネットワーク、ストレージなどの各領域の稼働率、性能、可用性、セキュリティといった項目ごとに、守るべき数値を明言した目標/評価基準です。 — location: [6539](kindle://book?action=open&asin=B09S5ZW33G&location=6539) ^ref-52502

---
キー制約 はExcelには存在していない機能で、入力内容をさらに厳密にチェックするための機能です。 — location: [6964](kindle://book?action=open&asin=B09S5ZW33G&location=6964) ^ref-31325

---
子テーブル（名前テーブル）は親テーブル（身長体重テーブル）に存在する値しか入力ができず、格納できるデータを制約できるようになります。 — location: [7004](kindle://book?action=open&asin=B09S5ZW33G&location=7004) ^ref-53660

---
また、子テーブル（名前テーブル）に特定のfeature_idが残っている場合は、親テーブル（身長体重テーブル）から特定コードを削除することができない制約も付与できます。 — location: [7006](kindle://book?action=open&asin=B09S5ZW33G&location=7006) ^ref-23658

---
View（ビュー）は元となるテーブルから必要な情報を取得して別の名前を付けた — location: [7070](kindle://book?action=open&asin=B09S5ZW33G&location=7070) ^ref-4738

---
ものです。 — location: [7071](kindle://book?action=open&asin=B09S5ZW33G&location=7071) ^ref-18927

---
COMMITまたはROLLBACK） — location: [7101](kindle://book?action=open&asin=B09S5ZW33G&location=7101) ^ref-16205

---
インデックス作成は、とくに名前テーブルに限られたものではなく、好きなテーブルの好きなカラムに付与することができます。 — location: [7133](kindle://book?action=open&asin=B09S5ZW33G&location=7133) ^ref-47653

---
クエリーエンジンとは、SQLを動かすソフトウェアやミドルウェアのことを指します。 — location: [7160](kindle://book?action=open&asin=B09S5ZW33G&location=7160) ^ref-22383

---
RDBもクエリーエンジンでMySQLもクエリーエンジンですし、SQL Serverもクエリーエンジンと呼ぶことが可能です。 — location: [7161](kindle://book?action=open&asin=B09S5ZW33G&location=7161) ^ref-16396

---

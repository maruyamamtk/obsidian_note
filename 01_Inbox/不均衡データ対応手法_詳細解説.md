# 不均衡データ対応手法：アンダーサンプリング・オーバーサンプリング詳細解説 #データサイエンス #機械学習  #統計 

## はじめに

機械学習において、クラス間のサンプル数に大きな偏りがある不均衡データ（imbalanced data）の処理は重要な課題です。本文書では、この問題に対処するためのサンプリング手法について、スモールデータ解析と機械学習の文献（kindle_page_20250506_231132.png以降）から抽出した内容を中心に詳しく解説します。

## 不均衡データの問題

### 基本的な問題
- **多数クラス偏重**: 分類器が多数クラスに偏った予測を行う
- **少数クラス軽視**: 重要な少数クラスの検出能力が低下
- **評価指標の歪み**: 正解率では真の性能を測定できない
- **実世界での重要性**: 医療診断、不正検知等では少数クラスが重要

### 具体的な影響
- 過学習の発生しやすさ
- 決定境界の偏り
- 特徴学習の偏重
- 汎化性能の低下

## アンダーサンプリング手法

多数クラスのサンプル数を減らしてバランスを調整する手法群。

### 1. ランダムアンダーサンプリング（Random Undersampling）

**概要**
- 多数クラスからランダムにサンプルを削除
- 最も基本的で実装が容易
- 計算コストが低い

**利点**
- 実装の簡単さ
- 計算時間の短縮
- メモリ使用量の削減

**欠点**
- 重要な情報の損失リスク
- データの代表性低下
- 偶然性に依存

**適用場面**
- 大規模データセット
- 計算リソースが限られている場合
- 初期の実験段階

### 2. Tomek Links

**概要**
- 異なるクラスの最近傍ペア（Tomek Link）を特定
- 多数クラス側のサンプルを優先的に除去
- クラス境界の明確化を図る

**アルゴリズム**
1. 全サンプル間の距離を計算
2. 異なるクラスの最近傍ペアを特定
3. Tomek Linkとなるペアの多数クラス側を除去

**特徴**
- ノイズ除去効果
- 決定境界の清浄化
- 質的なサンプル選択

**適用場面**
- ノイズの多いデータ
- 境界が曖昧なケース
- 高品質なデータセットが必要な場合

### 3. Edited Nearest Neighbours (ENN)

**概要**
- k近傍法を用いた編集型アンダーサンプリング
- 近傍情報に基づいてサンプルを除去
- 誤分類されやすいサンプルの特定

**アルゴリズム**
1. 各サンプルのk近傍を計算
2. 近傍の多数が異なるクラスの場合、そのサンプルを除去
3. 全サンプルに対して反復実行

**パラメータ**
- k値の設定（通常3～5）
- 距離指標の選択
- 除去基準の調整

**効果**
- 境界領域のノイズ除去
- 分類困難なサンプルの除去
- 決定境界の改善

### 4. Neighbourhood Cleaning Rule (NCL)

**概要**
- ENNを改良した手法
- より効果的なノイズ除去
- クラス境界の最適化

**改良点**
- 除去基準の洗練化
- より積極的なクリーニング
- 効率的なアルゴリズム

**適用効果**
- 高品質なデータセットの生成
- 分類性能の向上
- 過学習の抑制

## オーバーサンプリング手法

少数クラスのサンプル数を増やしてバランスを調整する手法群。

### 1. ランダムオーバーサンプリング（Random Oversampling）

**概要**
- 既存の少数クラスサンプルを単純に複製
- 最も基本的なオーバーサンプリング手法
- 実装が非常に簡単

**プロセス**
1. 少数クラスのサンプルをランダム選択
2. 選択されたサンプルを複製
3. 目標比率まで反復

**利点**
- 実装の容易さ
- 計算コストの低さ
- データの完全保持

**欠点**
- 過学習のリスク増大
- 新情報の不足
- 汎化能力の低下

### 2. SMOTE（Synthetic Minority Oversampling Technique）

**概要**
- 少数クラスの合成サンプルを生成
- 最も広く使用されるオーバーサンプリング手法
- 線形補間による新サンプル生成

**アルゴリズム**
1. 少数クラスの各サンプルについてk近傍を特定
2. 近傍からランダムに1つを選択
3. 元サンプルと選択サンプル間をランダム補間
4. 新しい合成サンプルを生成

**数式**
```
x_new = x_i + λ × (x_k - x_i)
```
- x_i: 元のサンプル
- x_k: k近傍の選択されたサンプル
- λ: [0,1]の乱数

**パラメータ**
- k値（通常5）
- 生成比率
- 距離指標

**利点**
- 新情報の創出
- 過学習の軽減
- 汎化能力の向上

**欠点**
- ノイズの増幅可能性
- 境界領域の曖昧化
- 計算コストの増加

### 3. ADASYN（Adaptive Synthetic Sampling）

**概要**
- SMOTEの改良版
- 学習困難な領域により多くのサンプルを生成
- 適応的な合成サンプル分布

**特徴**
- 密度ベースの生成数決定
- 境界領域への重点配置
- 多数クラスとの近接度考慮

**アルゴリズム**
1. 各少数クラスサンプルの近傍密度を計算
2. 密度に基づいて生成数を決定
3. 困難領域により多くのサンプルを配置

**効果**
- 境界学習の改善
- 分類困難領域の強化
- バランス取れた決定境界

### 4. Borderline-SMOTE

**概要**
- 境界線付近の少数クラスサンプルに焦点
- 効果的な決定境界学習の促進
- 計算効率の改善

**種類**
- **Borderline-SMOTE1**: 境界サンプルのみ使用
- **Borderline-SMOTE2**: 境界サンプル＋近傍多数クラス利用

**境界サンプルの定義**
- k近傍の半数以上が多数クラス
- かつ全てが多数クラスではない

**利点**
- 重要領域への集中
- 効率的な学習
- 性能向上の効果

### 5. 改良型SMOTE手法

#### SMOTE-NC（SMOTE for Nominal and Continuous）
- **対象**: カテゴリカル変数と連続変数の混在データ
- **手法**: カテゴリカル特徴には最頻値使用
- **効果**: 混合データタイプへの対応

#### SVM-SMOTE
- **概念**: SVM決定境界付近での生成
- **特徴**: サポートベクター近傍重視
- **効果**: 効果的な境界学習

## ハイブリッド手法

アンダーサンプリングとオーバーサンプリングを組み合わせた手法。

### 1. SMOTEENN

**概要**
- SMOTEとENNの組み合わせ
- 合成サンプル生成後のクリーニング
- 量と質の両方を改善

**プロセス**
1. SMOTEによるオーバーサンプリング
2. ENNによるノイズ除去
3. 高品質なバランスデータセット生成

**効果**
- 過学習の抑制
- ノイズの除去
- 分類性能の向上

### 2. SMOTETomek

**概要**
- SMOTEとTomek Linksの組み合わせ
- 境界明確化に特化
- クリーンな決定境界生成

**特徴**
- 境界ノイズの除去
- 決定境界の最適化
- 高精度な分類の実現

## アンサンブル手法との組み合わせ

### 1. BalancedBagging

**概要**
- バギングの各ベースモデルでサンプリング実行
- 多様性の確保と効率性の両立
- アンサンブル効果の最大化

**アルゴリズム**
1. 複数のベースモデルを用意
2. 各モデルに対してランダムアンダーサンプリング
3. 多数決またはアンサンブル予測

**利点**
- 計算効率の改善
- 多様性の確保
- 汎化性能の向上

### 2. BalancedRandomForest

**概要**
- ランダムフォレストの各決定木でサンプリング
- 特徴選択とサンプリングの同時実行
- 効率的な不均衡データ処理

**特徴**
- 自動的なサンプリング
- 高い予測精度
- 特徴重要度の計算

## コスト考慮型手法

### 1. Cost-sensitive Learning

**概要**
- 誤分類コストをクラス別に設定
- アルゴリズムレベルでの対応
- サンプリング不要のアプローチ

**手法**
- コスト行列の設定
- 損失関数の重み付け
- 決定関数の調整

**利点**
- 直接的な問題解決
- ドメイン知識の活用
- 柔軟なコスト設定

### 2. Threshold Moving

**概要**
- 分類境界の閾値調整
- 少数クラス検出率の向上
- ROC曲線上での最適化

**手法**
- 閾値の体系的探索
- 評価指標に基づく最適化
- バリデーションセットでの調整

**効果**
- 検出率の改善
- 実用的な性能調整
- コストを考慮した最適化

## 手法選択の指針

### データセットの特性による選択

#### 小規模データセット
- **推奨**: オーバーサンプリング手法
- **理由**: 情報損失の回避
- **具体例**: SMOTE、ADASYN

#### 大規模データセット
- **推奨**: アンダーサンプリング手法
- **理由**: 計算効率の重視
- **具体例**: Tomek Links、ENN

#### ノイズの多いデータセット
- **推奨**: ハイブリッド手法
- **理由**: クリーニング効果
- **具体例**: SMOTEENN、SMOTETomek

### 不均衡の程度による選択

#### 軽度の不均衡（比率 2:1 ～ 5:1）
- **推奨**: コスト考慮型手法
- **具体例**: Cost-sensitive、Threshold Moving

#### 中程度の不均衡（比率 5:1 ～ 20:1）
- **推奨**: SMOTE系手法
- **具体例**: SMOTE、Borderline-SMOTE

#### 重度の不均衡（比率 20:1以上）
- **推奨**: 改良型手法
- **具体例**: ADASYN、アンサンブル手法

### 計算リソースによる選択

#### 高速処理が必要
- **推奨**: ランダムサンプリング
- **理由**: 計算コストの最小化

#### 品質重視
- **推奨**: 改良型SMOTE、ハイブリッド手法
- **理由**: 高品質な合成データ生成

#### バランス重視
- **推奨**: アンサンブル手法
- **理由**: 効率と精度の両立

## 評価上の注意点

### 1. 適切な分割方法

**層化分割（Stratified Split）**
- 元の不均衡比率を維持
- 訓練・検証・テストの各セットでバランス保持
- 再現性のある評価の実現

### 2. 評価指標の選択

**不適切な指標**
- 正解率（Accuracy）のみの使用
- マクロ平均に偏った評価

**適切な指標**
- **Precision（適合率）**: 正確性の評価
- **Recall（再現率）**: 検出能力の評価  
- **F1-score**: バランスの取れた評価
- **AUC-PR**: 不均衡データ専用指標
- **G-mean**: 幾何平均による総合評価

### 3. 交差検証の実施

**層化k分割交差検証**
- 各分割で不均衡比率を維持
- 安定した性能評価の実現
- 過度な楽観的評価の回避

### 4. 実世界での検証

**ホールドアウトテスト**
- 完全に独立したテストセット
- 実運用環境での性能確認
- 汎化性能の真の評価

## 実装ライブラリ

### Python
- **imbalanced-learn**: 包括的なサンプリング手法
- **scikit-learn**: 基本的な手法
- **imblearn**: 専門ライブラリ

### R
- **SMOTE**: SMOTEの実装
- **DMwR**: データマイニング用ライブラリ
- **ROSE**: サンプリング手法集

### 実装例（Python）

```python
from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours
from imblearn.combine import SMOTEENN, SMOTETomek

# SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# ADASYN
adasyn = ADASYN(random_state=42)
X_resampled, y_resampled = adasyn.fit_resample(X, y)

# ハイブリッド手法
smote_enn = SMOTEENN(random_state=42)
X_resampled, y_resampled = smote_enn.fit_resample(X, y)
```

## まとめ

不均衡データの処理は機械学習における重要な課題であり、適切なサンプリング手法の選択が分類性能に大きく影響します。データセットの特性、計算リソース、要求される性能を総合的に考慮して、最適な手法を選択することが重要です。

また、サンプリング手法だけでなく、評価方法や実装方法についても慎重に検討し、実世界での適用を見据えた包括的なアプローチを取ることが成功の鍵となります。

## 参考文献

- スモールデータ解析と機械学習（第6章：分類）
	- [[詳細_第6章_分類]]
- 関連画像: kindle_page_20250506_231132.png ～ kindle_page_20250506_231148.png
- imbalanced-learn documentation
- He, H., & Garcia, E. A. (2009). Learning from imbalanced data. IEEE Transactions on knowledge and data engineering, 21(9), 1263-1284.

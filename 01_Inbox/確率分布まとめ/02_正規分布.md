# 正規分布 (Normal Distribution / Gaussian Distribution)

#統計

## 概要

正規分布は、統計学において最も重要かつ広く用いられる連続型確率分布の一つです。釣鐘型の対称な形状から「ガウス分布」とも呼ばれ、自然界や社会現象の多くの連続変数を記述します。

## 基本情報

- **種別**: 連続型
- **定義域**: $(-\infty, \infty)$
- **パラメータ**: μ（平均）, σ²（分散）
- **記法**: $X \sim N(\mu, \sigma^2)$

## 数学的性質

### 確率密度関数 (PDF)
$$f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left[-\frac{(x-\mu)^2}{2\sigma^2}\right]$$

### 標準正規分布 (μ=0, σ=1)
$$\phi(z) = \frac{1}{\sqrt{2\pi}} e^{-z^2/2}$$

### 統計的性質

- **平均（期待値）**: $E[X] = \mu$
- **分散**: $\text{Var}[X] = \sigma^2$
- **標準偏差**: $\sigma$
- **歪度**: 0（完全に対称）
- **尖度**: 3（超過尖度は0）

## 特徴と性質

### 形状の特徴
- **平均値 = 最頻値 = 中央値**: μで一致
- **左右対称**: 平均値μを中心として完全に対称
- **釣鐘型**: 平均から離れるほど確率密度が減少
- **漸近線**: x軸が漸近線（確率密度は0に近づくが0にはならない）

### 重要な性質

#### 68-95-99.7ルール
すべての正規分布で成り立つ性質：
- **μ ± 1σ**: 約68%のデータが含まれる
- **μ ± 1.96σ**: 約95%のデータが含まれる  
- **μ ± 3σ**: 約99.7%のデータが含まれる

### 数学的特性

- **再生性**: 独立な正規分布の線形結合も正規分布
- **最大エントロピー**: 与えられた平均と分散の下で最大エントロピー
- **中心極限定理**: 多くの分布の収束先

## 標準化

任意の正規分布を標準正規分布に変換：
$$Z = \frac{X - \mu}{\sigma} \sim N(0,1)$$

この変換により、異なるスケールの正規分布を比較可能になります。

## 中心極限定理

**定理**: 母集団の分布が何であれ、標本サイズnが十分大きければ、標本平均$\bar{X}$は近似的に正規分布に従う：

$$\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)$$

これは統計的推論の基礎となる極めて重要な定理です。

## モデリングへの応用

### 適用例

#### 自然科学・医学
- **身長・体重**: 人間の身体測定値
- **血圧・体温**: 生理学的指標
- **測定誤差**: 実験における観測誤差
- **薬物動態**: 血中濃度の時間変化

#### 教育・心理学
- **試験成績**: IQスコアや学力テスト結果
- **心理測定**: 性格特性の測定値
- **反応時間**: 認知実験での応答時間

#### 工学・技術
- **製品の品質**: 製造工程での寸法や重量
- **信号処理**: ガウシアンノイズ
- **画像処理**: 画像の輝度分布

#### 金融・経済
- **株価変動**: 対数収益率（しばしば正規分布に近似）
- **リスク管理**: VaR（Value at Risk）の計算
- **保険**: 保険金支払額の予測

## 再生性

正規分布の重要な性質として再生性があります：

$X_1 \sim N(\mu_1, \sigma_1^2)$ と $X_2 \sim N(\mu_2, \sigma_2^2)$ が独立のとき：
$$X_1 + X_2 \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$$

一般に、$a, b$ を定数とすると：
$$aX_1 + bX_2 \sim N(a\mu_1 + b\mu_2, a^2\sigma_1^2 + b^2\sigma_2^2)$$

## 統計的推論での役割

### 信頼区間
標本平均の95%信頼区間：
$$\bar{X} \pm 1.96 \frac{\sigma}{\sqrt{n}}$$

### 仮説検定
- **Z検定**: 標準正規分布を用いた検定
- **t検定**: 小標本での平均の検定
- **正規性の検定**: データが正規分布に従うかの検定

## 他の分布との関係

### 近似関係
- **二項分布**: $B(n,p) \approx N(np, np(1-p))$ (nが大きい場合)
- **ポアソン分布**: $\text{Poisson}(\lambda) \approx N(\lambda, \lambda)$ (λが大きい場合)

### 派生関係
- **カイ二乗分布**: 標準正規分布の二乗和
- **t分布**: 正規分布と標本分散の比
- **F分布**: 2つのカイ二乗分布の比

## 計算例

### 例題1: 標準化
$X \sim N(100, 15^2)$ で $P(X > 115)$ を求める：

$$Z = \frac{115 - 100}{15} = 1$$
$$P(X > 115) = P(Z > 1) = 1 - \Phi(1) \approx 0.159$$

### 例題2: 中心極限定理
平均50、標準偏差10の母集団から25個の標本を取る場合の標本平均の分布：

$$\bar{X} \sim N\left(50, \frac{10^2}{25}\right) = N(50, 4)$$

## Box-Muller変換

2つの独立な一様乱数から正規乱数を生成：

$$Z_1 = \sqrt{-2\ln U_1}\cos(2\pi U_2)$$
$$Z_2 = \sqrt{-2\ln U_1}\sin(2\pi U_2)$$

ここで、$U_1, U_2 \sim U(0,1)$ は独立で、$Z_1, Z_2 \sim N(0,1)$ は独立な標準正規乱数となります。

## 正規性の確認方法

### 視覚的方法
- **ヒストグラム**: 釣鐘型の形状確認
- **Q-Qプロット**: 理論分位数との比較
- **P-Pプロット**: 累積確率の比較

### 統計的検定
- **Shapiro-Wilk検定**: 小標本での正規性検定
- **Kolmogorov-Smirnov検定**: 分布の適合度検定
- **Anderson-Darling検定**: 裾部分を重視した検定

## 実装例（概念的）

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def normal_pdf(x, mu, sigma):
    """正規分布の確率密度関数"""
    return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)

def standardize(x, mu, sigma):
    """標準化"""
    return (x - mu) / sigma

def normal_properties(mu, sigma):
    """正規分布の統計的性質"""
    return {
        'mean': mu,
        'variance': sigma**2,
        'std': sigma,
        'skewness': 0,
        'kurtosis': 3,
        'interval_68': (mu - sigma, mu + sigma),
        'interval_95': (mu - 1.96*sigma, mu + 1.96*sigma),
        'interval_997': (mu - 3*sigma, mu + 3*sigma)
    }

def demonstrate_clt(population_dist, sample_sizes=[1, 5, 10, 30, 100], n_experiments=1000):
    """中心極限定理のデモンストレーション"""
    pop_mean = np.mean(population_dist)
    pop_var = np.var(population_dist)
    
    for n in sample_sizes:
        sample_means = []
        for _ in range(n_experiments):
            sample = np.random.choice(population_dist, n)
            sample_means.append(np.mean(sample))
        
        # 理論値との比較
        theoretical_mean = pop_mean
        theoretical_var = pop_var / n
        observed_mean = np.mean(sample_means)
        observed_var = np.var(sample_means)
        
        print(f"標本サイズ {n}:")
        print(f"  理論平均: {theoretical_mean:.3f}, 観測平均: {observed_mean:.3f}")
        print(f"  理論分散: {theoretical_var:.3f}, 観測分散: {observed_var:.3f}")
        
        # 正規性の検定
        _, p_value = stats.shapiro(sample_means)
        print(f"  Shapiro-Wilk検定 p値: {p_value:.3f}")

# 68-95-99.7ルールの確認
def verify_empirical_rule(mu=0, sigma=1, n_samples=100000):
    """68-95-99.7ルールの数値的確認"""
    samples = np.random.normal(mu, sigma, n_samples)
    
    within_1sigma = np.mean(np.abs(samples - mu) <= 1*sigma)
    within_2sigma = np.mean(np.abs(samples - mu) <= 2*sigma)
    within_3sigma = np.mean(np.abs(samples - mu) <= 3*sigma)
    
    print(f"1σ以内: {within_1sigma:.1%} (理論値: 68.3%)")
    print(f"2σ以内: {within_2sigma:.1%} (理論値: 95.4%)")
    print(f"3σ以内: {within_3sigma:.1%} (理論値: 99.7%)")
```

## 参考

詳細な参考文献については[[04_参考文献]]を参照してください。

## 関連項目

- [[標準正規分布]]
- [[02_カイ二乗分布]]
- [[t分布]]
- [[F分布]]
- [[中心極限定理]]
- [[03_確率分布間の関係性]]

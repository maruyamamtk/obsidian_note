# 第2章 主成分分析と次元削減

## 概要

本章では高次元データを扱う上で有効な「次元削減手法」、特に主成分分析（PCA）の理論と実装について詳細に解説している。PCAは統計学・機械学習において最も基本的かつ重要な手法の一つである。

## 主成分分析（PCA）の基本理論

### 定義と目的
主成分分析は、**データの分散を最大限に保った射影を求める手法**である。高次元データを低次元空間に射影する際に、元のデータの情報をできるだけ保持することを目的とする。

### 数学的導出
PCAは以下の方法によって導出される：
- **固有値分解（Eigenvalue Decomposition）**
- **特異値分解（Singular Value Decomposition; SVD）**

### 主成分の性質
- 主成分は**直交ベクトル**で構成される
- **第1主成分が最大分散**を持つ
- 第2主成分は第1主成分と直交しつつ、残りの分散を最大化する
- 以降の主成分も同様に構築される

## スモールデータにおけるPCAの課題

スモールデータにPCAを適用する際には、以下の注意が必要である：

### 主な問題点
1. **すべての主成分を採用すると条件数は改善しない**
   - 次元数がサンプル数を上回る場合、問題は根本的に解決されない

2. **主成分得点の分散が小さすぎると逆に不安定になる**
   - 低次の主成分を除外することで、かえって数値的不安定性が生じる可能性

3. **固有値の大きさを基準とした成分選択の根拠が乏しい**
   - 一般的な「累積寄与率○○%」といった基準に明確な理論的根拠がない

## 主成分の選択基準

筆者は、固有値の大きさのみを基準とした主成分の選択について疑問を呈し、**データごとの適応的判断の重要性**を説いている。以下の観点からの検討が必要：

- データの性質に応じた柔軟な判断
- 目的変数との関係性の考慮
- 実用性と解釈可能性のバランス

## 主成分回帰（PCR）

### 定義と特徴
主成分回帰（Principal Component Regression; PCR）は、**PCAと回帰分析を組み合わせた手法**である：

1. まずPCAで次元削減を行う
2. 得られた主成分を説明変数として回帰分析を実行

### 利点と限界
**利点**:
- 多重共線性の問題を回避できる
- 次元削減により計算が安定化する

**限界**:
- **入力のみに基づく次元削減では出力との関係が捨象される**
- 予測精度の観点で必ずしも最適ではない

## 次章への伏線

PCRの限界として「入力のみに基づく次元削減では出力との関係が捨象される」点が指摘されており、これは次章で扱う**PLS（部分最小二乗法）**との比較の伏線となっている。PLSは出力変数も考慮した次元削減を行うため、この問題を解決する手法として位置づけられる。

## まとめ

PCAは次元削減の基本的手法として重要だが、スモールデータでの適用には注意が必要である。特に主成分の選択については、固有値の大きさだけでなく、データの性質や目的に応じた適応的な判断が求められる。また、回帰における活用では、出力変数との関係性を考慮した手法（PLS等）との比較検討も重要である。

---

戻る: [[章ごとのまとめ]]
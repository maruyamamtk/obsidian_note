# 第6章 異常検知とスパース学習

## 概要

最終章では、スモールデータ環境下での異常検知技術と、スパース表現を活用した機械学習手法が紹介されている。これらの手法は、限られたデータの中から有用な情報を抽出し、異常な状態を検出するために重要な役割を果たす。

## 異常検知の基本概念

異常検知は、**正常なパターンから逸脱したデータポイントを特定する**タスクである。スモールデータでは、正常・異常の境界を正確に定義することが特に困難となる。

### スモールデータでの課題
- **正常データの不足**: 正常状態の統計的性質を把握するためのサンプルが限られる
- **異常データの希少性**: 異常事例が極めて少ない、または存在しない
- **高次元性**: 変数数がサンプル数を上回る状況での異常検知

## 密度ベース異常検知

### LOF（Local Outlier Factor）

LOFは、**サンプルの局所密度を利用して異常度を測定する手法**である。

#### 基本原理
1. **k近傍距離**: 各点のk番目に近い点との距離を算出
2. **到達可能密度**: 近傍点との距離に基づく局所密度の推定
3. **LOF値**: 対象点の密度と近傍点の密度の比較

#### 特徴と利点
- **局所的判断**: グローバルな分布に依存せず、局所的な密度変化を検出
- **クラスター形状への対応**: 複雑な形状のクラスターでも有効
- **実用性**: 様々な分野で実績のある手法

#### 計算手順
```
1. 各点のk近傍を特定
2. k距離(k-distance)を計算
3. 到達可能距離(reachability distance)を算出
4. 局所到達可能密度(LRD)を計算
5. LOF値 = 近傍点のLRD平均 / 対象点のLRD
```

### パラメータ設定
- **k値の選択**: データサイズと分布特性に応じた調整が必要
- **閾値設定**: LOF値に基づく異常判定の基準値

## 分離ベース異常検知

### iForest（Isolation Forest）

iForestは、**決定木ベースのアンサンブル手法**で、外れ値が**ルートに近いノードで分離されやすい性質**を利用して異常を検出する。

#### 基本アイデア
- **分離の容易さ**: 異常点は正常点よりも少ない分割で孤立させることができる
- **パス長**: ルートから葉ノードまでの経路長が短いほど異常度が高い

#### アルゴリズム
1. **ランダムサンプリング**: 元データからサブサンプルを抽出
2. **ランダム分割**: 各特徴量に対してランダムな分割点で二分木を構築
3. **アンサンブル**: 複数の分離木を組み合わせ
4. **異常スコア**: 各サンプルの平均パス長に基づく異常度算出

#### 利点
- **計算効率**: 線形時間複雑度でスケーラブル
- **パラメータ調整**: 比較的少ないハイパーパラメータ
- **ノイズ耐性**: ランダム性によりノイズに対して頑健

#### パラメータ
- **サブサンプルサイズ**: 通常256サンプル程度
- **木の数**: アンサンブルサイズ（通常100本程度）

## 統計的異常検知

### PCAベース異常検知

主成分分析を基盤とした異常検知では、**T²統計量とQ統計量**という2つの指標を用いる。

#### T²統計量（Hotelling's T²）
- **定義**: 主成分空間内でのマハラノビス距離
- **意味**: 正常な変動パターン内での異常度
- **計算**: 主成分得点の重み付き二乗和

#### Q統計量（SPE: Squared Prediction Error）
- **定義**: 主成分空間からの再構成誤差
- **意味**: モデルで説明できない変動
- **計算**: 元データと主成分による復元データの差の二乗和

#### 統合的評価
- **両統計量の併用**: T²とQの組み合わせによる多角的異常検知
- **信頼区間**: 統計的有意性に基づく異常判定閾値

## 非線形異常検知

### 自己符号化器（Autoencoder）

自己符号化器は、**非線形次元削減と復元誤差に基づく検出法**を提供する。

#### 基本構造
- **エンコーダ**: 入力データを低次元の潜在表現に圧縮
- **デコーダ**: 潜在表現から元の次元に復元
- **損失関数**: 入力と復元データの差（復元誤差）

#### 異常検知への応用
1. **正常データでの訓練**: 正常サンプルのみでモデルを学習
2. **復元誤差の計算**: テストデータに対する復元誤差を算出
3. **閾値判定**: 復元誤差が大きいサンプルを異常として判定

#### PCAとの関係
筆者が言及している重要な点として、**隠れ層に恒等関数を用いた場合、自己符号化器はPCAと等価**である。これは線形・非線形の架け橋として注目される特性である。

#### 利点と課題
**利点**:
- **非線形関係の学習**: 複雑なデータパターンに対応可能
- **柔軟性**: 様々なアーキテクチャで対応可能

**課題**:
- **訓練データの品質**: 正常データの代表性が重要
- **過学習**: 特にスモールデータでは注意が必要
- **解釈性**: ブラックボックス的側面

## 実運用上の考慮事項

### パラメータ設定

#### 信頼区間
統計的手法では、**信頼区間**の設定が重要：
- **95%信頼区間**: 一般的な設定、偽陽性率5%
- **99%信頼区間**: より保守的な設定、偽陽性率1%
- **問題領域に応じた調整**: コストと効果のバランス

#### Contamination比率
多くの異常検知手法では、**異常データの割合（contamination ratio）**を事前に設定する必要がある：
- **一般的設定**: 0.05～0.1（5%～10%）
- **ドメイン知識の活用**: 業界や問題特性に基づく調整
- **感度分析**: パラメータ変更による結果の安定性確認

### 評価手法

#### 評価指標
- **精度（Precision）**: 異常と判定したもののうち実際に異常だった割合
- **再現率（Recall）**: 実際の異常のうち検出できた割合
- **F1スコア**: 精度と再現率の調和平均
- **AUC**: ROC曲線下面積

#### 検証方法
- **交差検証**: データ分割による汎化性能評価
- **時系列分割**: 時系列データでは未来データでの検証
- **実運用テスト**: 実際の運用環境での性能確認

## 手法の使い分け

### 選択指針

各手法の特性を理解した上での適切な選択：

| 手法 | 適用場面 | 利点 | 注意点 |
|------|----------|------|--------|
| LOF | 局所的な異常 | クラスター形状に頑健 | パラメータ調整が重要 |
| iForest | 大規模データ | 高速・スケーラブル | ランダム性による変動 |
| PCA系 | 線形関係が主体 | 統計的解釈が容易 | 非線形関係を捉えられない |
| Autoencoder | 複雑な非線形関係 | 高い表現力 | 訓練データの質に依存 |

### 統合的アプローチ

実用的には、**複数手法の組み合わせ**が効果的：
- **アンサンブル異常検知**: 複数手法の結果を統合
- **段階的スクリーニング**: 高速手法→精密手法の順次適用
- **ドメイン知識との融合**: 統計的手法と専門知識の組み合わせ

## まとめ

スモールデータ環境での異常検知は、限られた情報から有用なパターンを抽出する高度な技術である。LOF、iForest、PCAベース手法、自己符号化器など、それぞれ異なる原理に基づく手法を適切に選択・組み合わせることで、効果的な異常検知システムを構築できる。重要なのは、手法の理論的背景を理解し、データの特性と問題要件に応じた適応的なアプローチを取ることである。また、実運用では信頼区間やcontamination比率などのパラメータ設定に加え、継続的な性能モニタリングと調整が欠かせない。

---

戻る: [[章ごとのまとめ]]
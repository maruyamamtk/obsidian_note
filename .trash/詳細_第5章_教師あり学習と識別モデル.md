# 第5章 教師あり学習と識別モデル

## 概要

本章では、分類問題に焦点をあて、識別モデルの構築法を詳細に扱っている。回帰問題とは異なる分類特有の課題と、それに対する効果的な解決策を提示している。

## 線形判別分析（LDA）

### 基本概念と目的

線形判別分析（Linear Discriminant Analysis; LDA）は、**クラス間分散を最大化しつつクラス内分散を最小化する**ような射影ベクトルを求める手法である。

### 数学的原理
LDAは以下の最適化問題を解く：
```
最大化: (クラス間分散) / (クラス内分散)
```

### 特徴と性質
- **次元削減と分類を同時に実現**: 高次元データを低次元空間に射影しながら分類性能を確保
- **最小二乗法との関係**: 最小二乗法の性質と通底する部分がある
- **多重共線性の影響**: 回帰分析と同様に多重共線性の影響を受けやすい

### スモールデータでの課題
- サンプル数が少ない場合、クラス内分散の推定が不安定になる
- 変数数がサンプル数を上回る場合、逆行列の計算が困難になる

## 分類性能の評価指標

### ROC曲線（Receiver Operating Characteristic curve）

ROC曲線は、**分類モデルの性能を可視化する強力なツール**である。

#### 構成要素
- **横軸**: 偽陽性率（False Positive Rate; FPR）
- **縦軸**: 真陽性率（True Positive Rate; TPR = 感度）
- **曲線**: 判定閾値を変化させたときの軌跡

#### 利点
- **単一の閾値に依存しない評価**: 様々な閾値での性能を総合的に評価
- **視覚的理解**: 性能の全体像を直感的に把握可能
- **モデル間比較**: 異なるモデルの性能を客観的に比較

### AUC（Area Under the Curve）

AUCは**ROC曲線下の面積**を表す指標である。

#### 特徴と解釈
- **数値範囲**: 0～1（0.5がランダム分類、1が完全分類）
- **統合指標**: ROC曲線の情報を一つの数値に集約
- **確率的解釈**: ランダムに選んだ正例と負例に対して、正例のスコアが負例より高い確率

#### 実用性
- **単一数値での性能比較**が可能
- **閾値設定の指針**として活用
- **不均衡データ**でも比較的安定した評価

## アンサンブル学習

### 基本概念

アンサンブル学習は、**複数の学習器を組み合わせて予測精度を向上させる**手法群である。スモールデータでも効果的であるとされている。

### バギング（Bagging）

#### 基本原理
- **Bootstrap Aggregating**の略
- 元データからブートストラップサンプリングで複数のデータセットを生成
- 各データセットで学習器を訓練
- 予測時は多数決（分類）または平均（回帰）で統合

#### 効果
- **分散の削減**: 個々の学習器の不安定性を平滑化
- **過学習の抑制**: 単一モデルよりも汎化性能が向上
- **並列処理**: 各学習器を独立に訓練可能

### ブースティング（Boosting）

#### 基本原理
- **逐次的学習**: 前の学習器の結果を次の学習器の学習に活用
- **誤分類サンプルの重視**: 前段で誤分類されたサンプルにより高い重みを付与
- **弱学習器の組み合わせ**: 単純な学習器を多数組み合わせて強力な学習器を構築

#### 特徴と効果
- **弱学習器の相互補完**: 各学習器が互いの弱点を補完
- **高い性能**: バギングよりも高い精度が得られることが多い
- **適応的学習**: データの特性に応じて学習プロセスが調整される

#### 代表的アルゴリズム
- **AdaBoost**: 重み付きサンプリングによる逐次学習
- **Gradient Boosting**: 勾配情報を利用した誤差の逐次修正
- **XGBoost**: 勾配ブースティングの高速・高精度実装

## スモールデータでのアンサンブル学習

### 効果的な理由

1. **分散削減効果**: 限られたデータでも複数の視点からの学習が可能
2. **過学習の抑制**: 単一モデルよりも汎化性能が安定
3. **ロバスト性**: 外れ値やノイズに対する耐性が向上

### 注意点

- **計算コスト**: 複数モデルの訓練・予測によるコスト増加
- **解釈性の低下**: 単一モデルよりも結果の解釈が困難
- **過学習リスク**: 特にブースティングでは訓練データに過適合する可能性

## 実用的な考慮事項

### モデル選択の指針

分類問題におけるモデル選択では、以下の要因を総合的に考慮する：

1. **データサイズ**: サンプル数と変数数の関係
2. **解釈性の要求**: ビジネス要件として説明可能性が必要か
3. **計算資源**: 訓練・予測にかけられる時間とコスト
4. **性能要求**: 必要な精度レベル

### 評価プロセス

効果的な分類モデル構築のためのプロセス：

1. **ベースライン設定**: 単純なモデル（ロジスティック回帰等）での性能確認
2. **複数手法の試行**: LDA、アンサンブル等の比較
3. **交差検証**: 汎化性能の客観的評価
4. **ROC/AUC分析**: 閾値設定と性能トレードオフの検討
5. **実運用テスト**: 実際のデータでの最終検証

## まとめ

分類問題におけるスモールデータ解析では、LDAによる次元削減と分類の同時実現、ROC曲線・AUCによる適切な性能評価、そしてアンサンブル学習による予測精度向上が重要な要素となる。特にアンサンブル学習は、限られたデータでも効果的に性能を向上させることができるため、スモールデータ環境での有力な選択肢である。ただし、解釈性や計算コストとのトレードオフを考慮した適切な手法選択が求められる。

---

戻る: [[章ごとのまとめ]]

# アンダーサンプリング（多数派クラスのサンプルを減らす）の例
#書籍詳細 #機械学習 #データサイエンス #不均衡データ #スモールデータ #サンプリング

アンダーサンプリングは、多数派クラスのサンプルを減らすことで、少数派クラスと多数派クラスのサンプル数を調整する手法です。

- **ランダムアンダーサンプリング (RUS)**:
    - これは最も単純な方法で、多数派クラスのサンプルをランダムに減らします。図5.9 でこの概念が示されています。
- **クラスタ基準アンダーサンプリング**:
    - この方法では、まず多数派クラスのサンプルをクラスターに分けます（例えば、K-平均法を使用）。
    - その後、各クラスターからランダムにサンプルを選択するか、クラスターの中心を代表サンプルとして採用することで、多数派クラスのサンプル数を減らします。図5.10 でその手順が示されています。
- **トメクリンク**:
    - これは、異なるクラスに属するサンプル間で、非常に近い位置にあるペア（トメクリンク）を特定し、そのうちの多数派クラスのサンプルを削除する方法です。
    - これにより、決定境界付近のアウトライヤーや、決定境界を不明瞭にする多数派サンプルが除去され、分類境界が明確になります。図5.11 はトメクリンクによって多数派クラスのサンプルが除去される様子を示しています。
- **サンプル生成型アンダーサンプリング**:
    - このアプローチでは、既存の多数派サンプルを利用して新しいサンプルを生成し、それを学習データとして使用します。

# オーバーサンプリング（少数派クラスのサンプルを増やす）の例

オーバーサンプリングは、少数派クラスのサンプルを人工的に増やすことで、データ分布の不均衡を改善する手法です。

- **SMOTE (Synthetic Minority Oversampling Technique)**:
    - この手法は、少数派クラスのサンプルを基に合成サンプルを生成します。
    - 具体的には、少数派クラスの特定のサンプルと、そのk-近傍点（最も近い隣接点）との間の線分上に新しいサンプルを作成します。図5.13 でSMOTEによるサンプル生成の概念が示されています。
- **ADASYN (Adaptive Synthetic Sampling)**:
    - SMOTEと同様に合成サンプルを生成しますが、ADASYNは少数派クラスが学習しにくい領域（例えば、決定境界付近）により多くのサンプルを適応的に生成します。
    - 各少数派サンプルに対して、学習の困難度に応じて生成する合成サンプルの数を比例的に増やします。図5.14 でその適応的な生成方法が示されています。
- **Borderline SMOTE**:
    - これはSMOTEの派生形であり、少数派クラスの中でも「決定境界線（Borderline）」上にあるサンプル、すなわち多数派クラスとの境界に近いサンプルに焦点を当てて合成サンプルを生成します。図5.15 でボーダーラインの概念が示されています。

これらの手法は、アンダーサンプリングとオーバーサンプリングを組み合わせて利用することも可能です。
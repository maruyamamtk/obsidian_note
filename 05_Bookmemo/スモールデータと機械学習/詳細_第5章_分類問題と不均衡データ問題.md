# 詳細_第5章_分類問題と不均衡データ問題

## 分類問題の概要

離散的なカテゴリを予測する**分類問題**と、機械学習においてしばしば課題となる**クラス間のサンプル数が著しく異なる「不均衡データ問題」**について解説している。

## 線形判別分析（LDA）

**線形判別分析（LDA）**は、分類のための次元削減手法の一つである。

### LDAの目的
**クラス間の平均の差を最大化し、かつクラス内のばらつきを最小化するような射影軸wを学習する**ことを目的とする。

### LDAの課題
**LDAはPCAと同様に次元削減とみなせるが、入力変数間に相関関係があると最小二乗法と同様にモデルが不安定になる（多重共線性）という問題も抱えている**。

## 分類モデルの性能評価

### 混同行列
分類モデルの性能評価には、以下の概念を用いた**混同行列**が利用される：
- **真陽性（TP）**
- **偽陽性（FP）**
- **真陰性（TN）**
- **偽陰性（FN）**

### 評価指標
混同行列から導出される評価指標：
- 感度
- 特異度
- F値

### ROC曲線とAUC
**ROC曲線とAUC（Area Under the Curve）**は、**カットオフ値の選択に依存しないモデルの全体的な性能評価**に役立つ重要なツールである。

## 不均衡データ問題への対処法

### サンプリング手法

不均衡データ問題に対しては、以下のサンプリング手法が紹介されている：

#### アンダーサンプリング
多数派クラスのサンプルを減らす手法。

#### オーバーサンプリング
少数派クラスのサンプルを増やす手法。代表的な手法：
- **SMOTE**
- **ADASYN**

これらの手法は、データの不均衡度を改善し、学習効率を高めることを目指す。
参考: [[オーバーサンプリング・アンダーサンプリングの例]]

### アンサンブル学習

複数の弱学習器を組み合わせる**アンサンブル学習**も不均衡データ解析に広く適用される：

- **バギング**
- **ブースティング**
- **ランダムフォレスト**

特に**ブースティングは、弱学習器が前の学習器の誤りを逐次的に修正していくことで、高い予測性能を達成しやすい**とされている。

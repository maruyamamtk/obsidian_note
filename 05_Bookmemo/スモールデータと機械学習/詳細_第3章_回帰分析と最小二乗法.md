# 詳細_第3章_回帰分析と最小二乗法

## 回帰分析の基本

回帰分析は、連続値の目的変数を予測するための機械学習の基本的なタスクである。

## 最小二乗法

その中でも最も基本的な手法が**最小二乗法**である。これは予測値と実際の値との残差の二乗和を最小化する回帰係数を求める方法である。

### ガウス・マルコフの定理

**ガウス・マルコフの定理**によれば、以下の仮定が満たされる場合、最小二乗推定量は**最良線形不偏推定量（BLUE）**となる：

- 誤差の平均がゼロ
- 等分散かつ無相関（**E[ε] = 0, Cov[ε] = σ²I**）

## スモールデータ特有の問題

実際のスモールデータ解析では、以下のような問題が発生しやすい：

- **入力変数間に強い相関がある「多重共線性」**
- **サンプル数（N）が入力変数の数（M）よりも少ない**

このような状況では最小二乗法が**不安定な結果**を出すか、**適用できない**場合がある。

## 解決手法

これらの課題を解決するために、以下の手法が紹介されている：

### 主成分回帰（PCR）

**PCRはPCAで次元削減を行うことで多重共線性を緩和する**。ただし、出力情報は考慮しない。

### リッジ回帰

**リッジ回帰は回帰係数にペナルティを課す**ことで係数の安定化を図る。

### 部分最小二乗法（PLS）

**PLSは入力と出力の両方の情報を考慮して共通の潜在変数を抽出し、次元削減と回帰を同時に行う**。そのため、スモールデータ解析において特に有効な手法とされている。

PLSモデルの構築には**NIPALSアルゴリズム**などが用いられる。

## モデル評価と最適化

### ハイパーパラメータ調整

モデルの最適な**ハイパーパラメータ（潜在変数の数など）の調整**には以下が活用される：
- **交差検定**
- **PRESS統計量**

### 性能評価指標

**回帰モデルの性能は以下の指標で評価される**：
- **RMSE（二乗平均平方根誤差）**
- **相関係数**
